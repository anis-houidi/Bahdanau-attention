{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:47.992279Z",
     "iopub.status.busy": "2022-07-24T18:28:47.991616Z",
     "iopub.status.idle": "2022-07-24T18:28:53.363991Z",
     "shell.execute_reply": "2022-07-24T18:28:53.363384Z"
    },
    "papermill": {
     "duration": 5.399991,
     "end_time": "2022-07-24T18:28:53.364237",
     "exception": false,
     "start_time": "2022-07-24T18:28:47.964246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023841,
     "end_time": "2022-07-24T18:28:53.413985",
     "exception": false,
     "start_time": "2022-07-24T18:28:53.390144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:53.467024Z",
     "iopub.status.busy": "2022-07-24T18:28:53.466363Z",
     "iopub.status.idle": "2022-07-24T18:28:53.476120Z",
     "shell.execute_reply": "2022-07-24T18:28:53.475508Z"
    },
    "papermill": {
     "duration": 0.037854,
     "end_time": "2022-07-24T18:28:53.476253",
     "exception": false,
     "start_time": "2022-07-24T18:28:53.438399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = open('./dialogs.txt','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:53.538609Z",
     "iopub.status.busy": "2022-07-24T18:28:53.536741Z",
     "iopub.status.idle": "2022-07-24T18:28:53.539265Z",
     "shell.execute_reply": "2022-07-24T18:28:53.539754Z"
    },
    "papermill": {
     "duration": 0.036137,
     "end_time": "2022-07-24T18:28:53.539892",
     "exception": false,
     "start_time": "2022-07-24T18:28:53.503755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "qna_list = [f.split('\\t') for f in file.split('\\n')]\n",
    "\n",
    "questions = [x[0] for x in qna_list]\n",
    "answers = [x[1] for x in qna_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:53.594556Z",
     "iopub.status.busy": "2022-07-24T18:28:53.593752Z",
     "iopub.status.idle": "2022-07-24T18:28:53.598152Z",
     "shell.execute_reply": "2022-07-24T18:28:53.598583Z"
    },
    "papermill": {
     "duration": 0.034261,
     "end_time": "2022-07-24T18:28:53.598714",
     "exception": false,
     "start_time": "2022-07-24T18:28:53.564453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  hi, how are you doing?\n",
      "Answer:  i'm fine. how about yourself?\n"
     ]
    }
   ],
   "source": [
    "print(\"Question: \", questions[0])\n",
    "print(\"Answer: \", answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  i'm fine. how about yourself?\n",
      "Answer:  i'm pretty good. thanks for asking.\n"
     ]
    }
   ],
   "source": [
    "print(\"Question: \", questions[1])\n",
    "print(\"Answer: \", answers[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024684,
     "end_time": "2022-07-24T18:28:53.648541",
     "exception": false,
     "start_time": "2022-07-24T18:28:53.623857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:53.706364Z",
     "iopub.status.busy": "2022-07-24T18:28:53.705749Z",
     "iopub.status.idle": "2022-07-24T18:28:53.709660Z",
     "shell.execute_reply": "2022-07-24T18:28:53.709232Z"
    },
    "papermill": {
     "duration": 0.036773,
     "end_time": "2022-07-24T18:28:53.710124",
     "exception": false,
     "start_time": "2022-07-24T18:28:53.673351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:53.812323Z",
     "iopub.status.busy": "2022-07-24T18:28:53.786579Z",
     "iopub.status.idle": "2022-07-24T18:28:53.983517Z",
     "shell.execute_reply": "2022-07-24T18:28:53.984078Z"
    },
    "papermill": {
     "duration": 0.249206,
     "end_time": "2022-07-24T18:28:53.984226",
     "exception": false,
     "start_time": "2022-07-24T18:28:53.735020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> hi , how are you doing ? <end>\n",
      "<start> i m fine . how about yourself ? <end>\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_sentence(questions[0]))\n",
    "print(preprocess_sentence(answers[0]))\n",
    "\n",
    "pre_questions = [preprocess_sentence(w) for w in questions]\n",
    "pre_answers = [preprocess_sentence(w) for w in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3725"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025708,
     "end_time": "2022-07-24T18:28:54.036529",
     "exception": false,
     "start_time": "2022-07-24T18:28:54.010821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:54.094147Z",
     "iopub.status.busy": "2022-07-24T18:28:54.093294Z",
     "iopub.status.idle": "2022-07-24T18:28:54.095255Z",
     "shell.execute_reply": "2022-07-24T18:28:54.095880Z"
    },
    "papermill": {
     "duration": 0.033088,
     "end_time": "2022-07-24T18:28:54.096062",
     "exception": false,
     "start_time": "2022-07-24T18:28:54.062974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:54.181740Z",
     "iopub.status.busy": "2022-07-24T18:28:54.180873Z",
     "iopub.status.idle": "2022-07-24T18:28:54.185617Z",
     "shell.execute_reply": "2022-07-24T18:28:54.186294Z"
    },
    "papermill": {
     "duration": 0.058212,
     "end_time": "2022-07-24T18:28:54.186499",
     "exception": false,
     "start_time": "2022-07-24T18:28:54.128287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(data, num_examples):\n",
    "    # creating cleaned input, output pairs\n",
    "    if(num_examples != None):\n",
    "        targ_lang, inp_lang, = data[:num_examples]\n",
    "    else:\n",
    "        targ_lang, inp_lang, = data\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:54.281522Z",
     "iopub.status.busy": "2022-07-24T18:28:54.280683Z",
     "iopub.status.idle": "2022-07-24T18:28:54.638248Z",
     "shell.execute_reply": "2022-07-24T18:28:54.639215Z"
    },
    "papermill": {
     "duration": 0.413461,
     "end_time": "2022-07-24T18:28:54.639453",
     "exception": false,
     "start_time": "2022-07-24T18:28:54.225992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_examples = 3000\n",
    "data = pre_answers, pre_questions\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(data, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3725, 24)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3725, 24)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:54.730122Z",
     "iopub.status.busy": "2022-07-24T18:28:54.728731Z",
     "iopub.status.idle": "2022-07-24T18:28:54.734333Z",
     "shell.execute_reply": "2022-07-24T18:28:54.733881Z"
    },
    "papermill": {
     "duration": 0.052894,
     "end_time": "2022-07-24T18:28:54.734511",
     "exception": false,
     "start_time": "2022-07-24T18:28:54.681617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2980 2980 745 745\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2980, 24)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026108,
     "end_time": "2022-07-24T18:28:54.787713",
     "exception": false,
     "start_time": "2022-07-24T18:28:54.761605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Word to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:54.848046Z",
     "iopub.status.busy": "2022-07-24T18:28:54.846131Z",
     "iopub.status.idle": "2022-07-24T18:28:54.848653Z",
     "shell.execute_reply": "2022-07-24T18:28:54.849125Z"
    },
    "papermill": {
     "duration": 0.035058,
     "end_time": "2022-07-24T18:28:54.849294",
     "exception": false,
     "start_time": "2022-07-24T18:28:54.814236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:54.908997Z",
     "iopub.status.busy": "2022-07-24T18:28:54.906524Z",
     "iopub.status.idle": "2022-07-24T18:28:54.912866Z",
     "shell.execute_reply": "2022-07-24T18:28:54.913857Z"
    },
    "papermill": {
     "duration": 0.038529,
     "end_time": "2022-07-24T18:28:54.913984",
     "exception": false,
     "start_time": "2022-07-24T18:28:54.875455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "4 ----> i\n",
      "241 ----> hate\n",
      "1383 ----> brushing\n",
      "29 ----> my\n",
      "1322 ----> teeth\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "9 ----> it\n",
      "12 ----> s\n",
      "440 ----> such\n",
      "11 ----> a\n",
      "2320 ----> chore\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028043,
     "end_time": "2022-07-24T18:28:54.970616",
     "exception": false,
     "start_time": "2022-07-24T18:28:54.942573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:56.877755Z",
     "iopub.status.busy": "2022-07-24T18:28:56.875077Z",
     "iopub.status.idle": "2022-07-24T18:28:56.938811Z",
     "shell.execute_reply": "2022-07-24T18:28:56.937933Z"
    },
    "papermill": {
     "duration": 1.940869,
     "end_time": "2022-07-24T18:28:56.938939",
     "exception": false,
     "start_time": "2022-07-24T18:28:54.998070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 24]), TensorShape([64, 24]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "print(BUFFER_SIZE)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025998,
     "end_time": "2022-07-24T18:28:56.990181",
     "exception": false,
     "start_time": "2022-07-24T18:28:56.964183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Encoder/Decoder with attention equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024735,
     "end_time": "2022-07-24T18:28:57.040372",
     "exception": false,
     "start_time": "2022-07-24T18:28:57.015637",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:57.099362Z",
     "iopub.status.busy": "2022-07-24T18:28:57.097302Z",
     "iopub.status.idle": "2022-07-24T18:28:57.099928Z",
     "shell.execute_reply": "2022-07-24T18:28:57.100362Z"
    },
    "papermill": {
     "duration": 0.034505,
     "end_time": "2022-07-24T18:28:57.100494",
     "exception": false,
     "start_time": "2022-07-24T18:28:57.065989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:57.155354Z",
     "iopub.status.busy": "2022-07-24T18:28:57.154825Z",
     "iopub.status.idle": "2022-07-24T18:28:59.217856Z",
     "shell.execute_reply": "2022-07-24T18:28:59.217238Z"
    },
    "papermill": {
     "duration": 2.092491,
     "end_time": "2022-07-24T18:28:59.218015",
     "exception": false,
     "start_time": "2022-07-24T18:28:57.125524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Encoder output shape: (batch size, sequence length, units) (64, 24, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025403,
     "end_time": "2022-07-24T18:28:59.269927",
     "exception": false,
     "start_time": "2022-07-24T18:28:59.244524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bahdanau Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:59.329344Z",
     "iopub.status.busy": "2022-07-24T18:28:59.328664Z",
     "iopub.status.idle": "2022-07-24T18:28:59.331766Z",
     "shell.execute_reply": "2022-07-24T18:28:59.331373Z"
    },
    "papermill": {
     "duration": 0.035839,
     "end_time": "2022-07-24T18:28:59.331889",
     "exception": false,
     "start_time": "2022-07-24T18:28:59.296050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):#decoder_hidden_sate, encoder hidden output\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        #values correspond aux hi\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:28:59.390952Z",
     "iopub.status.busy": "2022-07-24T18:28:59.390205Z",
     "iopub.status.idle": "2022-07-24T18:28:59.990652Z",
     "shell.execute_reply": "2022-07-24T18:28:59.989693Z"
    },
    "papermill": {
     "duration": 0.633664,
     "end_time": "2022-07-24T18:28:59.990784",
     "exception": false,
     "start_time": "2022-07-24T18:28:59.357120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n",
    "#print(attention_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025639,
     "end_time": "2022-07-24T18:29:00.043105",
     "exception": false,
     "start_time": "2022-07-24T18:29:00.017466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:29:00.103700Z",
     "iopub.status.busy": "2022-07-24T18:29:00.102998Z",
     "iopub.status.idle": "2022-07-24T18:29:00.105975Z",
     "shell.execute_reply": "2022-07-24T18:29:00.105575Z"
    },
    "papermill": {
     "duration": 0.036369,
     "end_time": "2022-07-24T18:29:00.106121",
     "exception": false,
     "start_time": "2022-07-24T18:29:00.069752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:29:00.165196Z",
     "iopub.status.busy": "2022-07-24T18:29:00.163733Z",
     "iopub.status.idle": "2022-07-24T18:29:00.207091Z",
     "shell.execute_reply": "2022-07-24T18:29:00.206264Z"
    },
    "papermill": {
     "duration": 0.074559,
     "end_time": "2022-07-24T18:29:00.207203",
     "exception": false,
     "start_time": "2022-07-24T18:29:00.132644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 2359)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02648,
     "end_time": "2022-07-24T18:29:00.260545",
     "exception": false,
     "start_time": "2022-07-24T18:29:00.234065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training\n",
    "\n",
    "1. Pass the input through the encoder which return encoder output and the encoder hidden state.\n",
    "2. The encoder output, encoder hidden state and the decoder input (which is the start token) is passed to the decoder.\n",
    "3. The decoder returns the predictions and the decoder hidden state.\n",
    "4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
    "5. Use teacher forcing to decide the next input to the decoder.\n",
    "6. Teacher forcing is the technique where the target word is passed as the next input to the decoder.\n",
    "7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:29:00.320105Z",
     "iopub.status.busy": "2022-07-24T18:29:00.319411Z",
     "iopub.status.idle": "2022-07-24T18:29:00.322793Z",
     "shell.execute_reply": "2022-07-24T18:29:00.322371Z"
    },
    "papermill": {
     "duration": 0.035356,
     "end_time": "2022-07-24T18:29:00.322896",
     "exception": false,
     "start_time": "2022-07-24T18:29:00.287540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:29:00.385300Z",
     "iopub.status.busy": "2022-07-24T18:29:00.383827Z",
     "iopub.status.idle": "2022-07-24T18:29:00.386052Z",
     "shell.execute_reply": "2022-07-24T18:29:00.386447Z"
    },
    "papermill": {
     "duration": 0.037289,
     "end_time": "2022-07-24T18:29:00.386574",
     "exception": false,
     "start_time": "2022-07-24T18:29:00.349285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:29:00.445746Z",
     "iopub.status.busy": "2022-07-24T18:29:00.444972Z",
     "iopub.status.idle": "2022-07-24T18:33:12.028754Z",
     "shell.execute_reply": "2022-07-24T18:33:12.030000Z"
    },
    "papermill": {
     "duration": 251.616963,
     "end_time": "2022-07-24T18:33:12.030219",
     "exception": false,
     "start_time": "2022-07-24T18:29:00.413256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 Loss:1.5333\n",
      "Epoch:  8 Loss:1.2816\n",
      "Epoch: 12 Loss:1.0868\n",
      "Epoch: 16 Loss:0.9280\n",
      "Epoch: 20 Loss:0.7753\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "    if(epoch % 4 == 0):\n",
    "        print('Epoch:{:3d} Loss:{:.4f}'.format(epoch,\n",
    "                                          total_loss / steps_per_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029737,
     "end_time": "2022-07-24T18:33:12.090263",
     "exception": false,
     "start_time": "2022-07-24T18:33:12.060526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:33:12.162326Z",
     "iopub.status.busy": "2022-07-24T18:33:12.161681Z",
     "iopub.status.idle": "2022-07-24T18:33:12.164627Z",
     "shell.execute_reply": "2022-07-24T18:33:12.164209Z"
    },
    "papermill": {
     "duration": 0.040048,
     "end_time": "2022-07-24T18:33:12.164740",
     "exception": false,
     "start_time": "2022-07-24T18:33:12.124692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_tags(sentence):\n",
    "    return sentence.split(\"<start>\")[-1].split(\"<end>\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:33:12.233000Z",
     "iopub.status.busy": "2022-07-24T18:33:12.232349Z",
     "iopub.status.idle": "2022-07-24T18:33:12.235446Z",
     "shell.execute_reply": "2022-07-24T18:33:12.235034Z"
    },
    "papermill": {
     "duration": 0.040954,
     "end_time": "2022-07-24T18:33:12.235554",
     "exception": false,
     "start_time": "2022-07-24T18:33:12.194600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return remove_tags(result), remove_tags(sentence)\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return remove_tags(result), remove_tags(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029662,
     "end_time": "2022-07-24T18:33:12.295328",
     "exception": false,
     "start_time": "2022-07-24T18:33:12.265666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Answer question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:33:12.359419Z",
     "iopub.status.busy": "2022-07-24T18:33:12.358721Z",
     "iopub.status.idle": "2022-07-24T18:33:12.361707Z",
     "shell.execute_reply": "2022-07-24T18:33:12.361258Z"
    },
    "papermill": {
     "duration": 0.03656,
     "end_time": "2022-07-24T18:33:12.361810",
     "exception": false,
     "start_time": "2022-07-24T18:33:12.325250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask(sentence):\n",
    "    result, sentence = evaluate(sentence)\n",
    "\n",
    "    print('Question: %s' % (sentence))\n",
    "    print('Predicted answer: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T18:33:12.426168Z",
     "iopub.status.busy": "2022-07-24T18:33:12.425423Z",
     "iopub.status.idle": "2022-07-24T18:33:12.502335Z",
     "shell.execute_reply": "2022-07-24T18:33:12.501479Z"
    },
    "papermill": {
     "duration": 0.111333,
     "end_time": "2022-07-24T18:33:12.502447",
     "exception": false,
     "start_time": "2022-07-24T18:33:12.391114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  i m fine . how about yourself ? \n",
      "Predicted answer: i m pretty good . thanks for asking . \n"
     ]
    }
   ],
   "source": [
    "ask(questions[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 271.634796,
   "end_time": "2022-07-24T18:33:14.848347",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-24T18:28:43.213551",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
